environment:
  name: "ant"
  # Add env-specific params like max_episode_steps if needed

sac_agent:
  actor_lr: 3e-4
  critic_lr: 1e-3
  alpha_lr: 3e-4
  gamma: 0.99
  tau: 0.005
  alpha: "auto" # Use 'auto' for automatic tuning, or a float value (e.g., 0.2)
  hidden_dim: 256
  target_update_interval: 1
  physics_grad_weight: 0.1 # Weight applied to the physics gradient loss term

training:
  buffer_capacity: 1000000
  batch_size: 256
  total_steps: 1000000
  start_steps: 5000    # Steps with random actions at the beginning
  update_freq: 1       # Agent updates per environment step
  physics_grad_ratio: 0.2 # Probability (0 to 1) of using physics grad update vs RL update
  interleave_rl_update: True # If True, perform RL update even when physics grad is used
  log_interval: 10000    # Log progress every N steps
  checkpoint_interval: 100000 # Save model checkpoint every N steps